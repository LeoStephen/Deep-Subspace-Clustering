{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from helpers import optimize\n",
    "from __future__ import print_function\n",
    "\n",
    "def getSparcityPrior(inputX, lambda1=0.01, lambda2=0.01, optimizer='Adam', epochs=10000, learning_rate=0.1, print_step=50):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    n_feat, n_sample = inputX.shape\n",
    "\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[n_feat, n_sample], name='X')\n",
    "    C = tf.Variable(tf.random_uniform([n_sample, n_sample], -1, 1), name='C')\n",
    "\n",
    "    loss = X - tf.matmul(X, C)\n",
    "    loss = tf.reduce_sum(tf.square(loss))\n",
    "\n",
    "    # Create sparseness in C\n",
    "    reg_lossC = tf.reduce_sum(abs(C))  # L1 loss for C\n",
    "\n",
    "    # Force the entries in the diagonal of C to be zero\n",
    "    reg_lossD = tf.trace(tf.square(C))\n",
    "\n",
    "    cost = loss + lambda1 * reg_lossC + lambda2 * reg_lossD\n",
    "    optimizer = optimize(cost, learning_rate, optimizer)\n",
    "    \n",
    "    # Optimizing the function\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for i in xrange(epochs):\n",
    "            sess.run(optimizer, feed_dict={X: inputX})\n",
    "            loss = sess.run(cost, feed_dict={X: inputX})\n",
    "            if i % print_step == 0:\n",
    "                print('epoch {0}: global loss = {1}'.format(i, loss))\n",
    "            C_val = sess.run(C)\n",
    "        \n",
    "        return C_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# ourdata = sio.loadmat(\"/Users/xupeng.tong/Documents/Data/OriginalData/B_mean_2labels.mat\")\n",
    "ourdata = sio.loadmat(\"/Volumes/TONY/Regeneron/Data/OriginalData/B_mean_2labels.mat\")\n",
    "\n",
    "inputX = ourdata['X']\n",
    "# inputX = normalize(inputX, axis=0)\n",
    "inputY = ourdata['Y'][0,:]\n",
    "columnNames = ourdata['columnNames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating C ...\n",
      "epoch 0: global loss = 2816743.5\n",
      "epoch 1: global loss = 31432867840.0\n",
      "epoch 2: global loss = 38608793600.0\n",
      "epoch 3: global loss = 16658131968.0\n",
      "epoch 4: global loss = 792171264.0\n",
      "epoch 5: global loss = 4700127232.0\n",
      "epoch 6: global loss = 16597424128.0\n",
      "epoch 7: global loss = 19419502592.0\n",
      "epoch 8: global loss = 11597244416.0\n",
      "epoch 9: global loss = 2496568832.0\n",
      "epoch 10: global loss = 239713872.0\n",
      "epoch 11: global loss = 4868051456.0\n",
      "epoch 12: global loss = 9819502592.0\n",
      "epoch 13: global loss = 9656833024.0\n",
      "epoch 14: global loss = 5109171712.0\n",
      "epoch 15: global loss = 817597888.0\n",
      "epoch 16: global loss = 325470720.0\n",
      "epoch 17: global loss = 3061357568.0\n",
      "epoch 18: global loss = 5502173696.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7f14c6253034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSparcityPrior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# dsc.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TONY/Regeneron/Codes/code_files/Clustering/Deep-Subspace-Clustering/sp.py\u001b[0m in \u001b[0;36mgetSparcityPrior\u001b[0;34m(inputX, C_init, lambda1, lambda2, optimizer, epochs, learning_rate, print_step)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating C ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TONY/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TONY/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TONY/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Volumes/TONY/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/TONY/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dsc import DeepSubspaceClustering\n",
    "from sp import getSparcityPrior\n",
    "\n",
    "c_init = np.full((inputX.shape[1],inputX.shape[1]), 0.1, dtype=np.float32)\n",
    "np.fill_diagonal(c_init, 0)\n",
    "\n",
    "C = getSparcityPrior(inputX, C_init=c_init, optimizer='Adam', lambda1=0.01, lambda2=50, epochs=500, learning_rate=0.1,print_step=1)\n",
    "# dsc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating C ...\n",
      "epoch 0: global loss = 185711.6875\n",
      "epoch 100: global loss = 1125.61914062\n",
      "epoch 200: global loss = 421.432098389\n",
      "epoch 300: global loss = 262.048248291\n",
      "epoch 400: global loss = 196.122955322\n",
      "epoch 500: global loss = 160.939468384\n",
      "epoch 600: global loss = 141.654968262\n",
      "epoch 700: global loss = 134.881256104\n",
      "epoch 800: global loss = 119.022529602\n",
      "epoch 900: global loss = 123.504333496\n",
      "epoch 1000: global loss = 105.935211182\n",
      "epoch 1100: global loss = 95.9519577026\n",
      "epoch 1200: global loss = 91.5889511108\n",
      "epoch 1300: global loss = 197.651321411\n",
      "epoch 1400: global loss = 119.350341797\n",
      "epoch 1500: global loss = 141.078125\n",
      "epoch 1600: global loss = 496.251861572\n",
      "epoch 1700: global loss = 184.521331787\n",
      "epoch 1800: global loss = 187.798233032\n",
      "epoch 1900: global loss = 372.561737061\n",
      "epoch 2000: global loss = 237.840179443\n",
      "epoch 2100: global loss = 122.25063324\n",
      "epoch 2200: global loss = 257.447418213\n",
      "epoch 2300: global loss = 450.617797852\n",
      "epoch 2400: global loss = 281.617980957\n",
      "epoch 2500: global loss = 235.727203369\n",
      "epoch 2600: global loss = 312.593902588\n",
      "epoch 2700: global loss = 195.309860229\n",
      "epoch 2800: global loss = 352.288146973\n",
      "epoch 2900: global loss = 193.096221924\n",
      "epoch 3000: global loss = 250.366836548\n",
      "epoch 3100: global loss = 129.655654907\n",
      "epoch 3200: global loss = 144.74899292\n",
      "epoch 3300: global loss = 439.946075439\n",
      "epoch 3400: global loss = 469.596099854\n",
      "epoch 3500: global loss = 119.992218018\n",
      "epoch 3600: global loss = 479.199249268\n",
      "epoch 3700: global loss = 374.111602783\n",
      "epoch 3800: global loss = 459.344787598\n",
      "epoch 3900: global loss = 364.981933594\n",
      "epoch 4000: global loss = 158.049682617\n",
      "epoch 4100: global loss = 195.524749756\n",
      "epoch 4200: global loss = 204.185012817\n",
      "epoch 4300: global loss = 192.933853149\n",
      "epoch 4400: global loss = 367.510192871\n",
      "epoch 4500: global loss = 147.995742798\n",
      "epoch 4600: global loss = 176.167617798\n",
      "epoch 4700: global loss = 206.407180786\n",
      "epoch 4800: global loss = 208.659011841\n",
      "epoch 4900: global loss = 269.088500977\n"
     ]
    }
   ],
   "source": [
    "from dsc import DeepSubspaceClustering\n",
    "from sp import getSparcityPrior\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test = np.random.randint(2, size=(100,100))\n",
    "c_init = np.full((100,100), 0.05, dtype=np.float32)\n",
    "# c_init = np.random.uniform(-0.1, 0.1, (20,20)).astype(np.float32)\n",
    "np.fill_diagonal(c_init, 0)\n",
    "\n",
    "keke = getSparcityPrior(test, C_init=None,optimizer='Adam', lambda1=0.001, lambda2=1000, epochs=5000, learning_rate=0.1,print_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.82652113e-04,   5.18126309e-01,  -2.08756462e-01, ...,\n",
       "         -3.08756948e-01,  -5.03817081e-01,  -4.90358770e-01],\n",
       "       [  5.17482579e-01,   7.30043103e-04,   1.06805682e-01, ...,\n",
       "          3.70522141e-02,   3.93671334e-01,   3.57290089e-01],\n",
       "       [ -6.17807031e-01,   2.95999974e-01,   2.40303285e-04, ...,\n",
       "         -9.90450919e-01,  -8.04429233e-01,  -6.10158801e-01],\n",
       "       ..., \n",
       "       [ -1.44622311e-01,   2.19002496e-02,  -1.84959263e-01, ...,\n",
       "          1.72013789e-03,  -2.39778459e-01,  -1.65782824e-01],\n",
       "       [ -9.42798495e-01,   6.81677163e-01,  -5.85100353e-01, ...,\n",
       "         -1.05005646e+00,   2.62108369e-04,  -6.86959326e-01],\n",
       "       [ -1.18184590e+00,   8.52450132e-01,  -5.39111853e-01, ...,\n",
       "         -9.09550786e-01,  -9.13012743e-01,   2.40702560e-04]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       ..., \n",
       "       [0, 1, 0, ..., 0, 1, 1],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
